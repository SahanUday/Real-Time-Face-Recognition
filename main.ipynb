{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "327fedc1-b42a-4f12-a619-a891d186ffb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition as fr\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37234787-d15c-4f9b-a01a-c6979abac1ee",
   "metadata": {},
   "source": [
    "### Function to calculate confidence level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7feb2826-d0ba-488b-9bc8-a6c77eb6277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_confidence(face_distance, face_match_threshold=0.6):\n",
    "    range_val = (1.0 - face_match_threshold)\n",
    "    linear_val = (1.0 - face_distance) / (range_val * 2.0)\n",
    "\n",
    "    if face_distance > face_match_threshold:\n",
    "        return str(round(linear_val * 100, 2)) + '%'\n",
    "    else:\n",
    "        value = (linear_val + ((1.0 - linear_val) * math.pow((linear_val - 0.5) * 2, 0.2))) * 100\n",
    "        return str(round(value, 2)) + '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cb7a9c-75bf-45ea-bcd2-b7ae570de851",
   "metadata": {},
   "source": [
    "# Face Recognition Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fc59e1a6-b604-45a1-8842-6b6372b866be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceRecognition:\n",
    "    face_locations = []\n",
    "    face_encodings = []\n",
    "    face_names = []\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "    process_current_frame = True\n",
    "    current_camera_index = 0  # Track the active webcam index\n",
    "\n",
    "    def __init__(self):\n",
    "        self.encode_faces()\n",
    "\n",
    "    # Encode known faces from the \"faces\" directory\n",
    "    def encode_faces(self):\n",
    "        print(\"Loading known faces...\")\n",
    "        for image in os.listdir('faces'): \n",
    "            face_image_path = os.path.join('faces', image)\n",
    "            face_image = fr.load_image_file(face_image_path)\n",
    "            face_encodings = fr.face_encodings(face_image)\n",
    "\n",
    "            self.known_face_encodings.append(face_encodings[0])\n",
    "            self.known_face_names.append(os.path.splitext(image)[0])  # Use file name without extension as name\n",
    "        \n",
    "        print(\"Known faces loaded:\", self.known_face_names)\n",
    "\n",
    "    # Run the face recognition process\n",
    "    def run_recognition(self):\n",
    "\n",
    "        # Video Capture\n",
    "        print(\"Starting video capture...\")\n",
    "        video_capture = cv2.VideoCapture(self.current_camera_index)\n",
    "\n",
    "        # Create a resizable window\n",
    "        cv2.namedWindow('Face Recognition', cv2.WINDOW_NORMAL)\n",
    "        is_fullscreen = False  # To toggle fullscreen mode\n",
    "\n",
    "        while True:\n",
    "            ret, frame = video_capture.read()\n",
    "\n",
    "            # Process every other frame for performance\n",
    "            if self.process_current_frame:\n",
    "                # Converts the frame from BGR to RGB (OpenCV captures images in BGR format, but face_recognition expects RGB.)\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # Optionally resize frame for faster processing\n",
    "                small_frame = cv2.resize(rgb_frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "                # Detect face locations\n",
    "                self.face_locations = fr.face_locations(small_frame, model=\"hog\")  # Switch to \"hog\" for CPU\n",
    "                if not self.face_locations:\n",
    "                    print(\"No face detected in this frame.\")\n",
    "                else:\n",
    "                    print(f\"Face Locations Detected: {self.face_locations}\")\n",
    "\n",
    "                # Compute face encodings for the detected faces\n",
    "                if self.face_locations:\n",
    "                        self.face_encodings = fr.face_encodings(small_frame, self.face_locations)\n",
    "                        print(\"Face encodings calculated successfully.\")\n",
    "                else:\n",
    "                    self.face_encodings = []\n",
    "\n",
    "                # Match each detected face with known faces\n",
    "                self.face_names = []    # Resets the list to store names and confidence\n",
    "                for face_encoding in self.face_encodings:\n",
    "                    matches = fr.compare_faces(self.known_face_encodings, face_encoding)\n",
    "\n",
    "                    #  Default Values\n",
    "                    name = \"Unknown\"\n",
    "                    confidence = \"Unknown\"\n",
    "\n",
    "                    face_distances = fr.face_distance(self.known_face_encodings, face_encoding)\n",
    "                    if face_distances.size > 0:\n",
    "                        best_match_index = np.argmin(face_distances)    # Finds the index of the smallest distance (closest match)\n",
    "\n",
    "                        if matches[best_match_index]:    # If matches[best_match_index] is True\n",
    "                            name = self.known_face_names[best_match_index]\n",
    "                            confidence = face_confidence(face_distances[best_match_index])\n",
    "\n",
    "                    self.face_names.append(f'{name} ({confidence})')\n",
    "\n",
    "            self.process_current_frame = not self.process_current_frame\n",
    "\n",
    "            # Display annotations on the frame\n",
    "            for (top, right, bottom, left), name in zip(self.face_locations, self.face_names):\n",
    "                # Scale back up face locations since the frame was resized to 1/4 size\n",
    "                top *= 4\n",
    "                right *= 4\n",
    "                bottom *= 4\n",
    "                left *= 4\n",
    "\n",
    "                # Draw a box around the face\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)    #Color: (0, 0, 255) (Red in BGR)/ Thickness: 2 pixels\n",
    "                # Draw a label with a name below the face\n",
    "                cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "\n",
    "                # Add text\n",
    "                cv2.putText(frame, name, (left + 6, bottom - 6), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255, 255, 255), 1)\n",
    "\n",
    "            # Display the resulting image in Face Recognition window\n",
    "            cv2.imshow('Face Recognition', frame)\n",
    "\n",
    "            # Handle keypress events (used to handle keyboard events in OpenCV applications)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "            # Switch cameras on 's'\n",
    "            if key == ord('s'):\n",
    "                print(\"Switching cameras...\")\n",
    "                video_capture.release()  # Release the current camera\n",
    "                self.current_camera_index = (self.current_camera_index + 1) % 2  # Toggle between 0 and 1\n",
    "                video_capture = cv2.VideoCapture(self.current_camera_index)\n",
    "                if not video_capture.isOpened():\n",
    "                    print(f\"Camera {self.current_camera_index} not available. Switching back.\")\n",
    "                    self.current_camera_index = (self.current_camera_index + 1) % 2\n",
    "                    video_capture = cv2.VideoCapture(self.current_camera_index)\n",
    "\n",
    "            # Quit on 'q'\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "\n",
    "        # Release handle to the webcam\n",
    "        video_capture.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdc702b-f390-4475-a2cd-15d4a2fdb793",
   "metadata": {},
   "source": [
    "### Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "285958a4-8be4-42a3-b286-5ee171aae351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
    
